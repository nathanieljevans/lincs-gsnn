{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb43b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from lincs_gsnn.data.DXDTDataset import DXDTDataset\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from lincs_gsnn.models.SplineWeightEmbedding import SplineWeightEmbedding\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sbn\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import networkx as nx \n",
    "import pickle as pkl\n",
    "\n",
    "from pypath.utils import mapping\n",
    "import warnings \n",
    "\n",
    "from pypath.utils import mapping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lincs_gsnn.models.ODEFunc import ODEFunc\n",
    "from lincs_gsnn.data.TrajDataset import TrajDataset\n",
    "from torchdiffeq import odeint \n",
    "\n",
    "import gseapy as gp\n",
    "from lincs_gsnn.explain.viz import annotate_edges, get_drug_edges, make_subgraph, plot_graph, axes_to_gif\n",
    "\n",
    "from lincs_gsnn.explain.infer_edge_weights import infer_edge_weights\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7c04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('/home/teddy/local/lincs-gsnn/workflow/runs/default/bionetwork/bionetwork.pt', weights_only=False)\n",
    "model = torch.load('../workflow/runs/default/pretrain/pretrained_model.pt', weights_only=False)\n",
    "dxdt_scale = torch.load('../workflow/runs/default/pretrain/dxdt_scale.pt', weights_only=False).item()\n",
    "x_names = pd.read_csv('/home/teddy/local/lincs-traj/workflow/runs/exp/default_v02/output/predict_grid/gene_names.csv')['gene_names'].values.astype(str)\n",
    "dxdt_meta = pd.read_csv('/home/teddy/local/lincs-traj/workflow/runs/exp/default_v02/output/predict_grid/dxdt_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1b09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = dxdt_meta[lambda x: (x.cell_iname == 'BT20') & (x.pert_id == 'BRD-K49328571')]\n",
    "\n",
    "target_genes = ['TP53']\n",
    "target_ix = [x_names.tolist().index(x) for x in target_genes if x in x_names] \n",
    "\n",
    "obs_dir = '/home/teddy/local/lincs-traj/workflow/runs/exp/default_v02/output/predict_grid/dxdt/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6066f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "dataset = DXDTDataset(\n",
    "                meta = cond, \n",
    "                obs_dir=obs_dir,\n",
    "                scale=dxdt_scale,\n",
    "                input_names=data.node_names_dict['input'],\n",
    "                return_time=True)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    persistent_workers=True)\n",
    "\n",
    "x, dxdt, t = next(iter(loader)) \n",
    "x = x.to(device)\n",
    "dxdt = dxdt.to(device)\n",
    "t = t.to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3daab08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 997])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21879b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(edge_mask): \n",
    "    print(edge_mask.shape)\n",
    "    dxdt = model(x, edge_mask=edge_mask)\n",
    "    return dxdt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eec7d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0256,  0.0388,  0.2799,  ...,  0.0787, -0.1916, -0.2103],\n",
       "        [ 0.0256,  0.0386,  0.2799,  ...,  0.0787, -0.1918, -0.2097],\n",
       "        [ 0.0253,  0.0387,  0.2800,  ...,  0.0787, -0.1915, -0.2099],\n",
       "        ...,\n",
       "        [ 0.0254,  0.0388,  0.2798,  ...,  0.0787, -0.1914, -0.2102],\n",
       "        [ 0.0256,  0.0385,  0.2799,  ...,  0.0788, -0.1917, -0.2101],\n",
       "        [ 0.0254,  0.0386,  0.2799,  ...,  0.0788, -0.1915, -0.2099]],\n",
       "       device='cuda:0', grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x, edge_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c237bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12800, 42564])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (12800) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m integrated_gradients \u001b[38;5;241m=\u001b[39m IntegratedGradients(func)\n\u001b[1;32m      2\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], model\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), device\u001b[38;5;241m=\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m attributions_ig \u001b[38;5;241m=\u001b[39m \u001b[43mintegrated_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/captum/log/dummy_log.py:39\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# pyre-fixme[53]: Captured variable `func` is not annotated.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# pyre-fixme[3]: Return type must be annotated.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/captum/attr/_core/integrated_gradients.py:289\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    277\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_baselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    299\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/captum/attr/_core/integrated_gradients.py:368\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    365\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    377\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    378\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    381\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/captum/_utils/gradient.py:128\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# _run_forward may return future of Tensor,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# but we don't support it here now\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# And it will fail before here.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m cast(Tensor, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/captum/_utils/common.py:588\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    585\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    586\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 588\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# pyre-fixme[60]: Concatenation not yet support for multiple variadic\u001b[39;49;00m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#  tuples: `*inputs, *additional_forward_args`.\u001b[39;49;00m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, torch\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mthen(\u001b[38;5;28;01mlambda\u001b[39;00m x: _select_targets(x\u001b[38;5;241m.\u001b[39mvalue(), target))\n",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mfunc\u001b[0;34m(edge_mask)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(edge_mask): \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(edge_mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     dxdt \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dxdt\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gsnn-lib/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/local/GSNN/gsnn/models/GSNN.py:640\u001b[0m, in \u001b[0;36mGSNN.forward\u001b[0;34m(self, x, node_mask, edge_mask, ret_edge_out, e0, node_errs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m    638\u001b[0m         x \u001b[38;5;241m=\u001b[39m mod(x, batch_params, node_err\u001b[38;5;241m=\u001b[39mnerr)\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edge_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43medge_mask\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m# under assumption that each layer output is iid unit normal (weak assumption since layer outputs will be correlated)\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;66;03m# then x = N(0,1) + N(0,1) + ... + N(0,1) = N(0, sqrt(layers))\u001b[39;00m\n\u001b[1;32m    644\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (12800) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "integrated_gradients = IntegratedGradients(func)\n",
    "edge_mask = torch.ones((x.shape[0], model.edge_index.shape[1],), device=device, requires_grad=True)\n",
    "attributions_ig = integrated_gradients.attribute(edge_mask, target=0, n_steps=200, baselines=torch.zeros_like(edge_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d7fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsnn-lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
